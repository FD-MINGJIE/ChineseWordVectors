{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练中文词向量\n",
    "\n",
    "这个demo展示Paddle如何训练中文的词向量模型。这里使用了处理过的维基百科中文语料作为训练语料。所有训练文件均分好词，放置在`wiki_data/data`目录中。\n",
    "\n",
    "首先我们先读取所有的文件，生成词表文件，并缓存到本地的目录中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import os\n",
    "import collections\n",
    "\n",
    "try:  # load word dict from disk\n",
    "    with open(\"word_dict.pkl\") as f:\n",
    "        word_dict = cPickle.load(f)\n",
    "except:  # generate word dict in the first time\n",
    "    print 'Generating word dictionary in the first time.'\n",
    "    word_dict = collections.defaultdict(int)\n",
    "    for dirpath, dirnames, filenames in os.walk(\"./wiki_data/data/\"):\n",
    "        if len(filenames) != 0:\n",
    "            for fn in filenames:\n",
    "                with open(os.path.join(dirpath, fn)) as f:\n",
    "                    for line in f:\n",
    "                        for w in line.strip().split():\n",
    "                            word_dict[w] += 1\n",
    "                            \n",
    "    items = list(word_dict.items())\n",
    "    items.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    word_dict = dict()\n",
    "    for i in xrange(len(items)):\n",
    "        word_dict[items[i][0]] = i\n",
    "    \n",
    "    print 'Saving to word_dict.pkl'\n",
    "    with open(\"word_dict.pkl\", \"w\") as f:\n",
    "        cPickle.dump(word_dict, f, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一步，我们开始读数据的过程。在读数据过程中，我们将词转换为词ID。由于数据量本身不大，所以我们将全部数据全部读入内存中即可。\n",
    "\n",
    "同时，我们丢弃低频词，从而加快训练过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORD_LIMIT=2000   # 只训练2000个词汇\n",
    "WINDOW_SIZE=11    # 训练窗口大小为11\n",
    "EMB_SIZE=32       # 设定词向量宽度\n",
    "NUM_PASSES = 20   # 设定训练轮数\n",
    "\n",
    "START_ID = WORD_LIMIT  # 句子开始标志\n",
    "END_ID = START_ID + 1  # 句子结束标志\n",
    "\n",
    "try:\n",
    "    with open(\"all_data.pkl\") as f:\n",
    "        all_data = cPickle.load(f)\n",
    "except:\n",
    "    print 'Converting words to word ids in the first time'\n",
    "    all_data = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(\"./wiki_data/data/\"):\n",
    "        for fn in filenames:\n",
    "            with open(os.path.join(dirpath, fn)) as f:\n",
    "                for line in f:\n",
    "                    line = [word_dict[w] for w in line.strip().split() if word_dict[w] < WORD_LIMIT]\n",
    "                    line = [START_ID] + line + [END_ID]\n",
    "                    if len(line) >= WINDOW_SIZE:\n",
    "                        all_data.append(line)\n",
    "    \n",
    "    print 'Saving to all_data.pkl'\n",
    "    with open(\"all_data.pkl\", 'w') as f:\n",
    "        cPickle.dump(all_data, f, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一步开始配置reader_creator。 reader_creator是Paddle的一个概念，用户通过自定义reader_creator定义Paddle的输入数据。reader_creator是一个函数，他返回一个reader函数，而reader函数是一个可以返回每一条数据的iterable的函数。简单示例如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def word_reader_creator():\n",
    "    def reader():\n",
    "        global all_data  # access all data below\n",
    "        random.shuffle(all_data)\n",
    "        for line in all_data:\n",
    "            for i in xrange(len(line) - WINDOW_SIZE + 1):\n",
    "                yield line[i:i+WINDOW_SIZE]  # yield word ids from 0 to WINDOW_SIZE\n",
    "    \n",
    "    return reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面开始配置神经网络，这里配置一个简单的CBOW网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.v2 as paddle\n",
    "paddle.init(use_gpu=False, trainer_count=3)\n",
    "words = [paddle.layer.data(name=\"word_%d\"%i, type=paddle.data_type.integer_value(WORD_LIMIT + 2)) \n",
    "         for i in xrange(WINDOW_SIZE)]\n",
    "\n",
    "embs = []\n",
    "for w in words[:WINDOW_SIZE / 2] + words[-WINDOW_SIZE / 2 + 1:]:\n",
    "    embs.append(paddle.layer.embedding(input=w, size=EMB_SIZE, param_attr=\n",
    "                                       paddle.attr.Param(name='emb', sparse_update=True)))\n",
    "\n",
    "with paddle.layer.mixed(size=EMB_SIZE) as sum_emb:\n",
    "    for emb in embs:\n",
    "        sum_emb += paddle.layer.identity_projection(input=emb)\n",
    "\n",
    "label = words[WINDOW_SIZE / 2]\n",
    "\n",
    "cost = paddle.layer.hsigmoid(input=sum_emb, label=label, num_classes=WORD_LIMIT+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面构建训练的参数，优化器，和trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = paddle.parameters.create(cost)\n",
    "optimizer = paddle.optimizer.RMSProp(learning_rate=1e-3)\n",
    "trainer = paddle.trainer.SGD(cost, parameters, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一步书写event_handler。Paddle的event handler是在训练过程中响应训练事件的回调函数，在这里用户可以对训练误差进行监控，保存模型等。\n",
    "\n",
    "进而开始训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir -p output\n",
    "import sys\n",
    "import gzip\n",
    "\n",
    "total_cost = 0.0\n",
    "counter = 0\n",
    "prefix=\"./output\"\n",
    "def event_handler(event):\n",
    "    global total_cost\n",
    "    global counter\n",
    "    if isinstance(event, paddle.event.EndIteration):\n",
    "        total_cost += event.cost\n",
    "        counter += 1\n",
    "        sys.stdout.write('.')\n",
    "        if event.batch_id % 100 == 0:\n",
    "            print \"Pass %d, Batch %d, AvgCost %f\" % (event.pass_id, event.batch_id, total_cost / counter)\n",
    "        if event.batch_id % 10000 == 0:\n",
    "            with gzip.open(os.path.join(prefix, \"model_%d_%d.tar.gz\" % (event.pass_id, event.batch_id)), 'w') as f:\n",
    "                parameters.to_tar(f)\n",
    "    if isinstance(event, paddle.event.EndPass):\n",
    "        print \"Pass %d\" % event.pass_id\n",
    "        with gzip.open(os.path.join(prefix, \"model_%d.tar.gz\" % event.pass_id), 'w') as f:\n",
    "            parameters.to_tar(f)\n",
    "\n",
    "trainer.train(paddle.batch(paddle.reader.buffered(word_reader_creator(), 16 * 4000), 3000),\n",
    "        num_passes=NUM_PASSES,\n",
    "        event_handler=event_handler,\n",
    "        feeding=[w.name for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，训练完20轮之后，所有的模型均保存在了output路径下，以备之后使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls -l ./output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
